{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/qslQhZblse9C3qNtXMCX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OgunmodedePeacePax/Brainwave_Matrix_Intern/blob/main/Brainwave_Intern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "fake_news_df = pd.read_csv('Fake.csv')\n",
        "true_news_df = pd.read_csv('True.csv')\n",
        "\n",
        "print(\"Fake News Dataset:\")\n",
        "print(fake_news_df.head())\n",
        "\n",
        "print(\"\\nTrue News Dataset:\")\n",
        "print(true_news_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydkGQNLwaP5K",
        "outputId": "49b4d906-3723-4878-e450-80fcbb727341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News Dataset:\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "2  On Friday, it was revealed that former Milwauk...    News   \n",
            "3  On Christmas day, Donald Trump announced that ...    News   \n",
            "4  Pope Francis used his annual Christmas Day mes...    News   \n",
            "\n",
            "                date  \n",
            "0  December 31, 2017  \n",
            "1  December 31, 2017  \n",
            "2  December 30, 2017  \n",
            "3  December 29, 2017  \n",
            "4  December 25, 2017  \n",
            "\n",
            "True News Dataset:\n",
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date  \n",
            "0  December 31, 2017   \n",
            "1  December 29, 2017   \n",
            "2  December 31, 2017   \n",
            "3  December 30, 2017   \n",
            "4  December 29, 2017   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fake News Dataset Shape:\", fake_news_df.shape)\n",
        "print(\"True News Dataset Shape:\", true_news_df.shape)\n",
        "\n",
        "print(\"\\nMissing values in Fake News Dataset:\")\n",
        "print(fake_news_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in True News Dataset:\")\n",
        "print(true_news_df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02Mn2mTSeids",
        "outputId": "864e3a6d-ad19-475d-ac34-6d3f40ee74c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News Dataset Shape: (23884, 4)\n",
            "True News Dataset Shape: (21417, 4)\n",
            "\n",
            "Missing values in Fake News Dataset:\n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in True News Dataset:\n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news_df['label'] = 0  # Label fake news as 0\n",
        "true_news_df['label'] = 1  # Label true news as 1\n",
        "\n",
        "combined_df = pd.concat([fake_news_df, true_news_df], ignore_index=True)\n",
        "\n",
        "combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(\"Combined and Shuffled Dataset:\")\n",
        "print(combined_df.head())\n"
      ],
      "metadata": {
        "id": "Qy-IqtVefISY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d638447f-17dd-4573-b32a-ad7434ef3144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined and Shuffled Dataset:\n",
            "                                               title  \\\n",
            "0  HOUSE INTEL Slaps Subpoenas on McCain Institut...   \n",
            "1  Exclusive: Trump's Afghan decision may increas...   \n",
            "2  Green groups fund-raise against Trump’s climat...   \n",
            "3  TRUMP’S WISCONSIN SPEECH Knocks It Out Of The ...   \n",
            "4  Islamic State claims responsibility for Aden c...   \n",
            "\n",
            "                                                text          subject  \\\n",
            "0  Please see our previous report below on the Mc...  Government News   \n",
            "1  ON BOARD A U.S. MILITARY AIRCRAFT (Reuters) - ...     politicsNews   \n",
            "2  WASHINGTON (Reuters) - Donald Trump’s promise ...     politicsNews   \n",
            "3  Donald Trump gave a rousing speech in Wisconsi...  Government News   \n",
            "4  CAIRO (Reuters) - Militant group Islamic State...        worldnews   \n",
            "\n",
            "                 date  label  \n",
            "0        Dec 27, 2017      0  \n",
            "1    August 22, 2017       1  \n",
            "2      June 10, 2016       1  \n",
            "3        Aug 17, 2016      0  \n",
            "4  November 29, 2017       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "combined_df['text'] = combined_df['text'].apply(clean_text)\n",
        "\n",
        "print(\"Cleaned Text Data:\")\n",
        "print(combined_df['text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-engZQvomp9",
        "outputId": "397c312a-4948-4119-c658-ddeea4d57c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text Data:\n",
            "0    please see our previous report below on the mc...\n",
            "1    on board a u s  military aircraft  reuters    ...\n",
            "2    washington  reuters    donald trump s promise ...\n",
            "3    donald trump gave a rousing speech in wisconsi...\n",
            "4    cairo  reuters    militant group islamic state...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "combined_df['text'] = combined_df['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Tokenized and Stop Words Removed Text Data:\")\n",
        "print(combined_df['text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycduWGtzo053",
        "outputId": "ae100c1e-12c5-41a7-ad7a-fe53d8b41ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized and Stop Words Removed Text Data:\n",
            "0    please see previous report mccain institute as...\n",
            "1    board u military aircraft reuters u air force ...\n",
            "2    washington reuters donald trump promise gut u ...\n",
            "3    donald trump gave rousing speech wisconsin las...\n",
            "4    cairo reuters militant group islamic state cla...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "X = tfidf_vectorizer.fit_transform(combined_df['text'])\n",
        "\n",
        "y = combined_df['label'].values\n",
        "\n",
        "print(\"TF-IDF Matrix Shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u-erjxWpWAN",
        "outputId": "d0103548-3938-4b70-8712-0ce8b294149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix Shape: (45301, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training Set Shape (X_train):\", X_train.shape)\n",
        "print(\"Training Labels Shape (y_train):\", y_train.shape)\n",
        "print(\"Testing Set Shape (X_test):\", X_test.shape)\n",
        "print(\"Testing Labels Shape (y_test):\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Xnx1CpqOEQ",
        "outputId": "f3b17051-bd0a-454d-c0bb-a27789b13e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape (X_train): (36240, 5000)\n",
            "Training Labels Shape (y_train): (36240,)\n",
            "Testing Set Shape (X_test): (9061, 5000)\n",
            "Testing Labels Shape (y_test): (9061,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression Model:\", accuracy)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paERXGiVqm-A",
        "outputId": "1af4860a-3203-43b3-dbab-c051fd1cae6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistic Regression Model: 0.9867564286502594\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4808\n",
            "           1       0.98      0.99      0.99      4253\n",
            "\n",
            "    accuracy                           0.99      9061\n",
            "   macro avg       0.99      0.99      0.99      9061\n",
            "weighted avg       0.99      0.99      0.99      9061\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4741   67]\n",
            " [  53 4200]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "print(\"Accuracy of Naive Bayes Model:\", nb_accuracy)\n",
        "\n",
        "print(\"\\nNaive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, nb_pred))\n",
        "\n",
        "print(\"\\nNaive Bayes Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, nb_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZASzygCiw9lY",
        "outputId": "668b2b1c-9f87-47f5-fa7a-4d147d84d117"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Naive Bayes Model: 0.9335614170621345\n",
            "\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4808\n",
            "           1       0.93      0.93      0.93      4253\n",
            "\n",
            "    accuracy                           0.93      9061\n",
            "   macro avg       0.93      0.93      0.93      9061\n",
            "weighted avg       0.93      0.93      0.93      9061\n",
            "\n",
            "\n",
            "Naive Bayes Confusion Matrix:\n",
            "[[4512  296]\n",
            " [ 306 3947]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_nb = {'alpha': [0.5, 1.0, 1.5, 2.0]}\n",
        "\n",
        "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search_nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters for Naive Bayes:\", grid_search_nb.best_params_)\n",
        "print(\"Best Accuracy for Naive Bayes:\", grid_search_nb.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjI9T8LWxiY4",
        "outputId": "0b790e3a-3b32-4e70-a8df-6b93c49ed5e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Naive Bayes: {'alpha': 0.5}\n",
            "Best Accuracy for Naive Bayes: 0.9338024282560706\n"
          ]
        }
      ]
    }
  ]
}